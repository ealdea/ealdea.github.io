
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<meta http-equiv="cache-control" content="no-cache">
<meta http-equiv="pragma" content="no-cache">
<meta http-equiv="expires" content="-1">
<link href="../css.css" type="text/css" rel="stylesheet"></link>

<script src='../hidebib.js' type="text/javascript"></script>

<title> Vision robotique </title>
</head>
<body bgcolor="#ffffff" link="#0000ff" text="#000000">

<div id="content-section">
    <div id="content-wrapper">
      <div id="content">

<p>

<font size="+1">Vision robotique - SETI</font>


<p></p><hr>
      <table bgcolor="#96c2fb" border="0" width="100%">
	<tbody><tr valign="bottom">
	  <td><font size="+2">Supports de cours</font></td>

	</tr>
	</tbody></table>

<br>
<ul>
<li> <a href=./3d-couleur.pdf>3D et couleur</a>
<li> <a href=./flot.pdf>Flot optique</a>
<li> <a href=./mviews.pdf>Multivues</a>
</ul>


<p></p><hr>
      <table bgcolor="#96c2fb" border="0" width="100%">
	<tbody><tr valign="bottom">
	  <td><font size="+2">Choix des papiers pour l'examen oral</font></td>

	</tr>
	</tbody></table>

<br>
<ul>
<li> date limite pour faire votre choix: <b><FONT COLOR="red">20 octobre 23:59</FONT></b> (après cette date, on le fera à votre place)
<li> premier venu, premier servi; la liste de papiers déjà pris sera affichée ici 
<li> pour choisir un papier, il faut m'envoyer  <b><FONT COLOR="red">exactement</FONT></b> le nombre demandé de participants,  <b><FONT COLOR="red">avec les autres en copie</FONT></b>. Toute autre demande sera ignorée (i.e. "je veux bien réserver ce papier, et je vous envoie le nom du binôme plus tard", ou "nous sommes deux, mais on veut choisir ce papier pour trois personnes" etc.)
</ul>

<p></p><hr>
      <table bgcolor="#96c2fb" border="0" width="100%">
	<tbody><tr valign="bottom">
	  <td><font size="+2">Papiers choisis:</font></td>
	</tr>
	</tbody></table>
<br>

<ul>
<li> Physical 3D Adversarial Attacks against Monocular Depth Estimation in Autonomous Driving - Jules Farnault, Thomas Boulanger<b><FONT COLOR="red"> slides en attente, rapport en attente </a> </FONT></b>
<li> High Accuracy Optical Flow Estimation Based on a Theory for Warping - Shuang Zhou, Kirollos Georges<b><FONT COLOR="red"> slides en attente, rapport en attente </a> </FONT></b>
<li> Tracking in dense crowds using prominence and neighborhood motion concurrence - Arnaud Feldmann, Hugo Allaire <b><FONT COLOR="red"> slides en attente, rapport en attente </a> </FONT></b>
<li> Non-Local Means Denoising  - Brahim Raies, Heidi Gad <b><FONT COLOR="red"> slides en attente, rapport en attente </a> </FONT></b>
<li> Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras  - Zélie Bascoulard, Abderraouf Bouchareb <b><FONT COLOR="red"> slides en attente, rapport en attente </a> </FONT></b>
<li> Locality-Aware Hyperspectral Classification  - Wissal Achour, Feriel Boudjatit <b><FONT COLOR="red"> slides en attente, rapport en attente </a> </FONT></b>
<li> ORB: an efficient alternative to SIFT or SURF  - Can Wang, Sean Woods <b><FONT COLOR="red"> slides en attente, rapport en attente </a> </FONT></b>
<li> BRISK: Binary Robust Invariant Scalable Keypoints  - Hocine Abdoun, Hassan Chehaitly <b><FONT COLOR="red"> slides en attente, rapport en attente </a> </FONT></b>

</ul>

<b> Localisation de l'examen: </b> <b><FONT COLOR="green"> Bâtiment 660 DIGITEO, salle 2014. Pour y arriver: <a href=../directions.html> plan </a> </FONT></b>  <b><FONT COLOR="red">Arriver à 13h15 avec une pièce d'identité: un contrôle sécurité est en place dans le bâtiment.</FONT></b> <br>
<b> Ordre de passage: </b> <b><FONT COLOR="green"> affichage final ici à partir du 21 octobre</FONT></b>

<table>
  <colgroup>
    <col style="width:65%">
    <col style="width:20%">
    <col style="width:15%">
  </colgroup>  
  <tr>
    <th>Titre papier</th>
    <th>Etudiants</th>
    <th>Heure</th>
  </tr>
  <tr>
    <td>Physical 3D Adversarial Attacks against Monocular Depth Estimation in Autonomous Driving </td>
    <td>Jules Farnault, Thomas Boulanger </td>
    <td>13h30 - 13h50</td>
  <tr>
  <tr>
    <td>High Accuracy Optical Flow Estimation Based on a Theory for Warping </td>
    <td>Shuang Zhou, Kirollos Georges </td>
    <td>13h50 - 14h10</td>
  <tr>
  <tr>
    <td>Tracking in dense crowds using prominence and neighborhood motion concurrence </td>
    <td>Arnaud Feldmann, Hugo Allaire </td>
    <td>14h10 - 14h30</td>
  </tr>
  <tr>
    <td>Non-Local Means Denoising </td>
    <td>Brahim Raies, Heidi Gad </td>
    <td>14h30 - 14h50</td>
  </tr>
  <tr>
    <td>Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras </td>
    <td>Zélie Bascoulard, Abderraouf Bouchareb </td>
    <td>14h50 - 15h10</td>
  </tr>
  <tr>
    <td>Pause </td>
    <td> &nbsp; </td>
    <td>15h10 - 15h30</td>
  </tr>
  <tr>
    <td>Locality-Aware Hyperspectral Classification </td>
    <td>Wissal Achour, Feriel Boudjatit </td>
    <td>15h30 - 15h50</td>
  </tr>
  <tr>
    <td>ORB: an efficient alternative to SIFT or SURF  </td>
    <td>Can Wang, Sean Woods </td>
    <td>15h50 - 16h10</td>
  </tr>
  <tr>
    <td>BRISK: Binary Robust Invariant Scalable Keypoints  </td>
    <td>Hocine Abdoun, Hassan Chehaitly </td>
    <td>16h10 - 16h30</td>
  </tr> 
</table>


<p></p><hr>
      <table bgcolor="#96c2fb" border="0" width="100%">
	<tbody><tr valign="bottom">
	  <td><font size="+2">Concernant l'examen oral:</font></td>
	</tr>
	</tbody></table>
<br>

<ul>
<li> date limite pour envoyer les transparents de votre présentation, en format <b>PDF</b>: <b><FONT COLOR="red">24 novembre 23:59</FONT></b>; date de l'examen oral: <b><FONT COLOR="red">28 novembre 13h30-18h00</FONT></b>. Ces dates sont fermes. <b>Ne m'envoyez pas de fichiers PPT, PPTX etc.</b>
<li> vous pouvez rendre par email le rapport accompagnant votre travail au moment de l'examen
<li> vous pouvez utiliser français ou anglais pour les transparents ou pour le rapport. Néanmoins, l'objectif est de résumer le papier avec vos mots, et le copier-coller sera drastiquement sanctionné. 
<li> durée de votre présentation: 5' par personne (donc 10' pour un binôme, et 15' pour un trinôme)
<li> votre présence pendant toute la durée de l'examen est obligatoire
<li> suggestion du contenu de la présentation pour un binôme: <b><FONT COLOR="red">1'30</FONT></b> : présentation du problème et enjeux; <b><FONT COLOR="red">1'30</FONT></b> : travaux connexes; <b><FONT COLOR="red">6'</FONT></b> : contributions scientifiques du papier et résultats; <b><FONT COLOR="red">1'</FONT></b> : conclusion, éventuelles limitations du travail présenté.
</ul>

<p></p><hr>
      <table bgcolor="#96c2fb" border="0" width="100%">
	<tbody><tr valign="bottom">
	  <td><font size="+2">Questions à traiter dans le rapport:</font></td>
	</tr>
	</tbody></table>
<br>

<ul>
<li> Replacer l’article à analyser dans le contexte général du traitement d’images: par exemple, de quelle grande classe de problèmes traite-t-il? Lien avec les thématiques vues en cours? Vous aider des mots clés: par exemple, présenter chacun d’eux (ou presque) en partant des aspects traitement d’image vers l’application.
<li> Replacer l’article dans son contexte de recherche : par exemple, quel est le problème traité ? quels sont les méthodes déjà existantes ? Vous aider de l’introduction. En outre, vous sélectionnerez un article dans la bibliographie ou trouvé sur le web pour positionner l’article que vous allez analyser par rapport à cet autre article.
<li> Expliquer ce que vous avez appris de l’article, qu’il s’agisse de connaissances techniques, applicatives, etc. Imaginez dans quel(s) cas vous pourriez réutiliser ces connaissances : par exemple, en les transposant à une autre application, ou en déduisant un principe algorithmique général.
<li> Si vous aviez à traiter le même problème, que reprendriez-vous de l’article et sur quoi essaieriez-vous autre chose ? précisez cet ‘autre chose’.
</ul>


<p></p><hr>
      <table bgcolor="#96c2fb" border="0" width="100%">
	<tbody><tr valign="bottom">
	  <td><font size="+2">Liste de papiers</font></td>
	</tr>
	</tbody></table>
<br>

<b><FONT COLOR="red"> Mettez vos binômes en copie lors de l'envoi de votre choix, ce qui m’évite de chercher leurs adresses mail dans l'annuaire de l’université!!</FONT></b>
<!-- <b><FONT COLOR="green"> (disponible)</FONT></b> -->

<ol>

<li> <b>Titre</b>: Un papier au choix de BMVC 2023<b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : Les papiers sont relativement accessibles. <br>
	<a href=https://proceedings.bmvc2023.org/>Consultez la liste des papiers acceptés</a>
	
<li> <b>Titre</b>: Un papier au choix de CVPR 2024<b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : Attention, le choix est très large, mais certains papiers sont difficiles. <br>
	<a href=https://openaccess.thecvf.com/CVPR2024?day=all>Consultez la liste des papiers acceptés</a>

<li> <b>Titre</b>: SCALE-INVARIANT CORNER KEYPOINTS (2014)<b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : Effective and efficient generation of keypoints from images
is the first step of many computer vision applications, such
as object matching. The last decade presented us with an
arms race toward faster and more robust keypoint detection,
feature description and matching. This resulted in several
new algorithms, for example Scale Invariant Features
Transform (SIFT), Speed-up Robust Feature (SURF),
Oriented FAST and Rotated BRIEF (ORB) and Binary
Robust Invariant Scalable Keypoints (BRISK). The
keypoint detection has been improved using various
techniques in most of these algorithms. However, in the
search for faster computing, the accuracy of the algorithms
is decreasing. In this paper, we present SICK (Scale-
Invariant Corner Keypoints), which is a novel method for
fast keypoint detection. Our experiment results show that
SICK is faster to compute and more robust than recent state-
of-the-art methods.<br>
	<a href=./pdfs/1569897927_sickkeypts.pdf>Télécharger pdf</a>

<li> <b>Titre</b>: MARKED POINT PROCESS MODEL FOR FACIAL WRINKLE DETECTION (2014) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : We propose a new model for wrinkle detection in human faces us-
ing a marked point process. In order to detect an arbitrary shape of
wrinkles, we represent them as a set of line segments, where each
segment is characterized by its length and orientation. We propose a
probability density of wrinkle model which exploits local edge pro-
file and geometric properties of wrinkles. To optimize the proba-
bility density of wrinkle model, we employ reversible jump Markov
chain Monte Carlo sampler with delayed rejection. Experimental
results demonstrate that the new algorithm detects facial wrinkles
more accurately than a recent state-of-the-art method.<br>
	<a href=./pdfs/1569899971_MPPwrinkle.pdf>Télécharger pdf</a>

<li> <b>Titre</b>: Joint A Contrario Ellipse and Line Detection (2016) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : Abstract—We propose a line segment and elliptical arc detector that produces a reduced number of false detections on various types
of images without any parameter tuning. For a given region of pixels in a grey-scale image, the detector decides whether a line
segment or an elliptical arc is present (model validation). If both interpretations are possible for the same region, the detector chooses
the one that best explains the data (model selection). We describe a statistical criterion based on the a contrario theory, which serves
for both validation and model selection. The experimental results highlight the performance of the proposed approach compared to
state-of-the-art detectors, when applied on synthetic and real images.<br>
	<a href=./pdfs/patraucean2016.pdf>Télécharger pdf</a>

	<li> <b>Titre</b>: WATERPIXELS: SUPERPIXELS BASED ON THE WATERSHED TRANSFORMATION (2014) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : Many sophisticated segmentation algorithms rely on a first
low-level segmentation step where an image is partitioned
into homogeneous regions with enforced compactness and
adherence to object boundaries. These regions are called “su-
perpixels”. While the marker controlled watershed transfor-
mation should in principle be well suited for this type of ap-
plication, it has never been seriously tested in this setup, and
comparisons to other methods were not made with the best
possible settings.
Here, we provide a scheme for applying the watershed
transform for superpixel generation, where we use a spatially
regularized gradient to achieve a tunable trade-off between
superpixel regularity and adherence to object boundaries. We
quantitatively evaluate our method on the Berkeley segmenta-
tion database and show that we achieve comparable results to
a previously published state-of-the art algorithm, while avoid-
ing some of the arbitrary postprocessing steps the latter re-
quires.<br>
	<a href=./pdfs/1569914047_waterpixels.pdf>Télécharger pdf</a>

	

	

	


	<li> <b>Titre</b>: Tracking in dense crowds using prominence and neighborhood
motion concurrence (2014) <b><FONT COLOR="red"> (pris)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : Methods designed for tracking in dense crowds typically employ prior knowledge to make this difficult problem
tractable. In this paper, we show that it is possible to handle this problem, without any priors, by utilizing the
visual and contextual information already available in such scenes.
We propose a novel tracking method tailored to dense crowds which provides an alternative and complementary
approach to methods that require modeling of crowd flow and, simultaneously, is less likely to fail in the case of
dynamic crowd flows and anomalies by minimally relying on previous frames. Our method begins with the au-
tomatic identification of prominent individuals from the crowd that are easy to track. Then, we use Neighborhood
Motion Concurrence to model the behavior of individuals in a dense crowd, this predicts the position of an indi-
vidual based on the motion of its neighbors. When the individual moves with the crowd flow, we use Neighbor-
hood Motion Concurrence to predict motion while leveraging five-frame instantaneous flow in case of
dynamically changing flow and anomalies. All these aspects are then embedded in a framework which imposes
hierarchy on the order in which positions of individuals are updated. Experiments on a number of sequences
show that the proposed solution can track individuals in dense crowds without requiring any pre-processing,
making it a suitable online tracking algorithm for dense crowds.<br>
	<a href=./pdfs/color-salient-heads.pdf>Télécharger pdf</a>

	<li> <b>Titre</b>: High Accuracy Optical Flow Estimation Based on a
Theory for Warping (2004) <b><FONT COLOR="red"> (pris)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : We study an energy functional for computing optical flow that com-
bines three assumptions: a brightness constancy assumption, a gradient constancy
assumption, and a discontinuity-preserving spatio-temporal smoothness constraint.
In order to allow for large displacements, linearisations in the two data terms are
strictly avoided. We present a consistent numerical scheme based on two nested
fixed point iterations. By proving that this scheme implements a coarse-to-fine
warping strategy, we give a theoretical foundation for warping which has been
used on a mainly experimental basis so far. Our evaluation demonstrates that the
novel method gives significantly smaller angular errors than previous techniques
for optical flow estimation. We show that it is fairly insensitive to parameter vari-
ations, and we demonstrate its excellent robustness under noise.<br>
	<a href=./pdfs/brox-flot.pdf>Télécharger pdf</a>

	<li> <b>Titre</b>: Visual Tracking: An Experimental Survey (2014) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 3 <br>
     <b>Remarques</b>: difficile; peut continuer en mini-projet <br>
     <b>Résumé</b> : There is a large variety of trackers, which have been proposed in the literature during the last two decades with some
mixed success. Object tracking in realistic scenarios is a difficult problem, therefore, it remains a most active area of research in
computer vision. A good tracker should perform well in a large number of videos involving illumination changes, occlusion, clutter,
camera motion, low contrast, specularities, and at least six more aspects. However, the performance of proposed trackers have been
evaluated typically on less than ten videos, or on the special purpose datasets. In this paper, we aim to evaluate trackers
systematically and experimentally on 315 video fragments covering above aspects. We selected a set of nineteen trackers to include
a wide variety of algorithms often cited in literature, supplemented with trackers appearing in 2010 and 2011 for which the code was
publicly available. We demonstrate that trackers can be evaluated objectively by survival curves, Kaplan Meier statistics, and Grubs
testing. We find that in the evaluation practice the F-score is as effective as the object tracking accuracy (OTA) score. The analysis
under a large variety of circumstances provides objective insight into the strengths and weaknesses of trackers.<br>
	<a href=./pdfs/tracking-survey.pdf>Télécharger pdf</a>

	<li> <b>Titre</b>: Global Fusion of Relative Motions for Robust, Accurate
and Scalable Structure from Motion (2013) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 3 <br>
     <b>Remarques</b>: difficile <br>
     <b>Résumé</b> : Multi-view structure from motion (SfM) estimates the po-
sition and orientation of pictures in a common 3D coordi-
nate frame. When views are treated incrementally, this ex-
ternal calibration can be subject to drift, contrary to global
methods that distribute residual errors evenly. We propose a
new global calibration approach based on the fusion of rel-
ative motions between image pairs. We improve an existing
method for robustly computing global rotations. We present
an efficient a contrario trifocal tensor estimation method,
from which stable and precise translation directions can be
extracted. We also define an efficient translation registra-
tion method that recovers accurate camera positions. These
components are combined into an original SfM pipeline.
Our experiments show that, on most datasets, it outperforms
in accuracy other existing incremental and global pipelines.
It also achieves strikingly good running times: it is about 20
times faster than the other global method we could compare
to, and as fast as the best incremental method. More impor-
tantly, it features better scalability properties.<br>
	<a href=http://imagine.enpc.fr/~moulonp/publis/iccv2013/>Télécharger pdf</a>

	<li> <b>Titre</b>: EDLines: A real-time line segment detector with a false detection control (2011) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : We propose a linear time line segment detector that gives accurate results, requires no parameter tuning,
and runs up to 11 times faster than the fastest known line segment detector in the literature; namely, the
line segment detector (LSD) by Grompone von Gioi et al. The proposed algorithm makes use of the clean,
contiguous (connected) chain of edge pixels produced by our novel edge detector, the Edge Drawing (ED)
algorithm; hence the name EDLines. The detector includes a line validation step due to the Helmholtz
principle, which lets it control the number of false detections. With its accurate results and blazing speed,
EDLines will be very suitable for the next generation real-time computer vision and image processing
applications.<br>
	<a href=./pdfs/EDLines-PRL.pdf>Télécharger pdf</a>

	

	

	<li> <b>Titre</b>: Non-Iterative Approach for Fast and Accurate Vanishing Point Detection (2009) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : We present an algorithm that quickly and accurately es-
timates vanishing points in images of man-made environ-
ments. Contrary to previously proposed solutions, ours is
neither iterative nor relies on voting in the space of van-
ishing points. Our formulation is based on a recently pro-
posed algorithm for the simultaneous estimation of multiple
models called J-Linkage. Our method avoids representing
edges on the Gaussian sphere and the computations and er-
ror measures are done in the image. We show that a consis-
tency measure between a vanishing point and an edge of the
image can be computed in closed-form while being geomet-
rically meaningful. Finally, given a set of estimated vanish-
ing points, we show how this consistency measure can be
used to identify the three vanishing points corresponding to
the Manhattan directions. We compare our algorithm with
other approaches on the York Urban Database and show
significant performance improvements.<br>
	<a href=./pdfs/JVPs.pdf>Télécharger pdf</a>

	<li> <b>Titre</b>: KEYPOINT DETECTION BY CASCADED FAST (2014) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : When the FAST method for detecting corner features at high
speed is applied to images that include complex textures
(regions that include foliage, shrubbery, etc.), many corners
that are not needed for object recognition are detected be-
cause FAST defines corner features on the basis of a 16-pixel
bounding circle. To overcome that problem, we propose the
Cascaded FAST that defines corners on the basis of similarity
in terms of intensity, continuity and orientation in a broader
range of areas (20, 16, and 12 pixel bounding circles). Also,
cascading three decision trees trained by the FAST approach
enables high-speed corner detection in which non-corners
are eliminated early in the process. Furthermore, Cascaded
FAST determines scale by using an image pyramid and de-
termines orientation at high speed by using a framework for
referencing surrounding pixels.<br>
	<a href=./pdfs/cascaded-fast.pdf>Télécharger pdf</a>

	<li> <b>Titre</b>: BRISK: Binary Robust Invariant Scalable Keypoints (2011) <b><FONT COLOR="red"> (pris)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : Effective and efficient generation of keypoints from an
image is a well-studied problem in the literature and forms
the basis of numerous Computer Vision applications. Es-
tablished leaders in the field are the SIFT and SURF al-
gorithms which exhibit great performance under a variety
of image transformations, with SURF in particular consid-
ered as the most computationally efficient amongst the high-
performance methods to date.
In this paper we propose BRISK, a novel method for
keypoint detection, description and matching. A compre-
hensive evaluation on benchmark datasets reveals BRISK’s
adaptive, high quality performance as in state-of-the-art al-
gorithms, albeit at a dramatically lower computational cost
(an order of magnitude faster than SURF in cases). The
key to speed lies in the application of a novel scale-space
FAST-based detector in combination with the assembly of
a bit-string descriptor from intensity comparisons retrieved
by dedicated sampling of each keypoint neighborhood.<br>
	<a href=./pdfs/brisk.pdf>Télécharger pdf</a>

	<li> <b>Titre</b>: ORB: an efficient alternative to SIFT or SURF (2011) <b><FONT COLOR="red"> (pris)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : Feature matching is at the base of many computer vi-
sion problems, such as object recognition or structure from
motion. Current methods rely on costly descriptors for de-
tection and matching. In this paper, we propose a very fast
binary descriptor based on BRIEF, called ORB, which is
rotation invariant and resistant to noise. We demonstrate
through experiments how ORB is at two orders of magni-
tude faster than SIFT, while performing as well in many
situations. The efficiency is tested on several real-world ap-
plications, including object detection and patch-tracking on
a smart phone.<br>
	<a href=./pdfs/orb.pdf>Télécharger pdf</a>

	

	<li> <b>Titre</b>: UNSUPERVISED TEXTURE SEGMENTATION USING MONOGENIC CURVELETS AND
THE POTTS MODEL (2014) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : We present a method for the unsupervised segmenta-
tion of textured images using Potts functionals, which are a
piecewise-constant variant of the Mumford and Shah func-
tionals. We propose a minimization strategy based on the
alternating direction method of multipliers and dynamic pro-
gramming. The strategy allows us to process large feature
spaces because the computational cost grows only linearly in
the feature dimension. In particular, our algorithm has more
favorable computational costs for high-dimensional data than
graph cuts. Our feature vectors are based on monogenic
curvelets. They incorporate multiple resolutions and direc-
tional information. The advantage over classical curvelets
is that they yield smoother amplitudes due to the envelope
effect of the monogenic signal.<br>
	<a href=./pdfs/unser.pdf>Télécharger pdf</a>

	<li> <b>Titre</b>: Reducing Multiclass to Binary:
A Unifying Approach for Margin Classifiers (2000) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 3 <br>
     <b>Remarques</b>: difficile <br>
     <b>Résumé</b> : We present a unifying framework for studying the solution of multiclass categorization prob-
lems by reducing them to multiple binary problems that are then solved using a margin-based
binary learning algorithm. The proposed framework unifies some of the most popular approaches
in which each class is compared against all others, or in which all pairs of classes are compared
to each other, or in which output codes with error-correcting properties are used. We propose a
general method for combining the classifiers generated on the binary problems, and we prove a
general empirical multiclass loss bound given the empirical loss of the individual binary learning
algorithms. The scheme and the corresponding bounds apply to many popular classification learn-
ing algorithms including support-vector machines, AdaBoost, regression, logistic regression and
decision-tree algorithms. We also give a multiclass generalization error analysis for general output
codes with AdaBoost as the binary learner. Experimental results with SVM and AdaBoost show
that our scheme provides a viable alternative to the most commonly used multiclass algorithms.<br>
	<a href=./pdfs/jmlr.pdf>Télécharger pdf</a>

	<li> <b>Titre</b>: Online error correcting output codes (2011) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : This article proposes a general extension of the error correcting output codes framework to the online
learning scenario. As a result, the final classifier handles the addition of new classes independently of
the base classifier used. In particular, this extension supports the use of both online example incremental
and batch classifiers as base learners. The extension of the traditional problem independent codings one-
versus-all and one-versus-one is introduced. Furthermore, two new codings are proposed, unbalanced
online ECOC and a problem dependent online ECOC. This last online coding technique takes advantage
of the problem data for minimizing the number of dichotomizers used in the ECOC framework while pre-
serving a high accuracy. These techniques are validated on an online setting of 11 data sets from UCI data-
base and applied to two real machine vision applications: traffic sign recognition and face recognition. As
a result, the online ECOC techniques proposed provide a feasible and robust way for handling new classes
using any base classifier.<br>
	<a href=./pdfs/ecoc2011.pdf>Télécharger pdf</a>

	
	<li> <b>Titre</b>: Robust Wide Baseline Pose Estimation from Video (2016) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : Robust wide baseline pose estimation is an essential
step in the deployment of smart camera networks. In this work,
we highlight some current limitations of conventional strategies
for relative pose estimation in difficult urban scenes. Then we
propose a solution which relies on an adaptive search of corresponding interest points in synchronized video streams which
allows us to converge robustly towards a high-quality solution.
The experiments are performed using a manually annotated
ground truth of a large scale scene exhibiting significant depth
and perspective variation, uniform areas, repetitive patterns and
homogeneous dynamic elements. The results show a fast and robust convergence of the solution, and a significant improvement,
compared to single image based alternatives, of the RMSE of
ground truth matches, and of the maximum absolute error.<br>
	<a href=./pdfs/PellicanoICPR16.pdf>Télécharger pdf</a>


	<li> <b>Titre</b>: Geometry-Based Multiple Camera Head Detection in Dense Crowds (2017) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : This paper addresses the problem of head detection in crowded environments. Our
detection is based entirely on the geometric consistency across cameras with overlap-
ping fields of view, and no additional learning process is required. We propose a fully
unsupervised method for inferring scene and camera geometry, in contrast to existing
algorithms which require specific calibration procedures. Moreover, we avoid relying on
the presence of body parts other than heads or on background subtraction, which have
limited effectiveness under heavy clutter. We cast the head detection problem as a stereo
MRF-based optimization of a dense pedestrian height map, and we introduce a constraint
which aligns the height gradient according to the vertical vanishing point direction. We
validate the method in an outdoor setting with varying pedestrian density levels. With
only three views, our approach is able to detect simultaneously tens of heavily occluded
pedestrians across a large, homogeneous area.<br>
	<a href=./pdfs/PellicanoAMMDS17.pdf>Télécharger pdf</a>

<li> <b>Titre</b>: Robust Epipolar Geometry Estimation Using Noisy Pose Priors (2017) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : Epipolar geometry estimation is fundamental to many computer vision algorithms. It has therefore attracted a lot
of interest in recent years, yielding high quality estimation algorithms for wide baseline image pairs. Currently
many types of cameras such as smartphones produce geo-tagged images containing pose and internal calibration data.
These include a GPS receiver, which estimates the position, a compass, accelerometers, and gyros, which estimate the
orientation, and the focal length. Exploiting this information as part of an epipolar geometry estimation algorithm may
be useful but not trivial, since the pose measurement may be quite noisy. We introduce SOREPP (Soft Optimization
method for Robust Estimation based on Pose Priors), a novel estimation algorithm designed to exploit pose priors
naturally. It sparsely samples the pose space around the measured pose and for a few promising candidates applies
a robust optimization procedure. It uses all the putative correspondences simultaneously, even though many of them
are outliers, yielding a very efficient algorithm whose runtime is independent of the inlier fraction. SOREPP was
extensively tested on synthetic data and on hundreds of real image pairs taken by smartphones. Its ability to handle
challenging scenarios with extremely low inlier fractions of less than 10% was demonstrated. It outperforms current
state-of-the-art algorithms that do not use pose priors as well as others that do.<br>
	<a href=./pdfs/SOREPP.pdf>Télécharger pdf</a>

<li> <b>Titre</b>: Learning to Find Good Correspondences (2018) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : We develop a deep architecture to learn to find good correspondences for wide-baseline stereo. Given a set of pu-
tative sparse matches and the camera intrinsics, we train
our network in an end-to-end fashion to label the correspondences as inliers or outliers, while simultaneously using them to recover the relative pose, as encoded by the
essential matrix. Our architecture is based on a multi-layer
perceptron operating on pixel coordinates rather than directly on the image, and is thus simple and small. We intro-
duce a novel normalization technique, called Context Normalization, which allows us to process each data point separately while embedding global information in it, and also
makes the network invariant to the order of the correspondences. Our experiments on multiple challenging datasets
demonstrate that our method is able to drastically improve
the state of the art with little training data.<br>
	<a href=./pdfs/corresp18.pdf>Télécharger pdf</a>

<li> <b>Titre</b>: Integrating Visual and Geometric Consistency for Pose Estimation (2019) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : In this work, we tackle the problem of estimating the relative pose between two cameras in urban environments in the presence of additional information provided by low quality localization and orientation sensors. An M-estimator based approach provides an elegant solution for the fusion between inertial and vision data, but it is sensitive to the prior importance of the visual matches between the two views. In addition to using cues extracted from local visual similarity, we propose to rely at the same time on learned associations provided by the global geometrical coherence. A conservative weighting scheme for combining the two types of cues has been proposed and validated successfully on an urban dataset.<br>
	<a href=../pdfs/ChenMVA19.pdf>Télécharger pdf</a>


<li> <b>Titre</b>: Implementation of the Midway Image Equalization (2016) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : In this paper, we present the detailed algorithm of the Midway Image Equalization giving to a
pair of images the same histogram while maintaining as much as possible their previous gray
dynamics. The midway equalization is primarily designed for gray level images, but can be
applied channel-wise to color images. This method is easy to implement, fast to compute, fully
automatic and requires no parameter.<br>
	<a href=./pdfs/implementation_of_the_midway_image_equalization.pdf>Télécharger pdf</a>

<li> <b>Titre</b>: Modified Bilateral Filter for the Restoration of Noisy Color Images (2012) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : In the paper a novel technique of noise removal in color images is presented. The proposed filter design is a modification of the
bilateral denosing scheme, which considers the similarity of color pixels and their spatial distance. However, instead of direct calculation of
the dissimilarity measure, the cost of a connection through a digital path
joining the central pixel of the filtering window and its neighbors is determined. The filter output, like in the standard bilateral filter, is calculated
as a weighted average of the pixels which are in the neighborhood relation
with the center of the filtering window, and the weights are functions of
the minimal connection costs. Experimental results prove that the new
denoising method yields significantly better results than the bilateral filter in case of color images contaminated by strong mixed Gaussian and
impulsive noise.<br>
	<a href=./pdfs/modified_bilateral_filter_for_the_restoration_of_noisy_color_images.pdf>Télécharger pdf</a>


<li> <b>Titre</b>: Non-Local Means Denoising (2011) <b><FONT COLOR="red"> (pris)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : We present in this paper a new denoising method called non-local means. The method is based
on a simple principle: replacing the color of a pixel with an average of the colors of similar
pixels. But the most similar pixels to a given pixel have no reason to be close at all. It is
therefore licit to scan a vast portion of the image in search of all the pixels that really resemble
the pixel one wants to denoise. The paper presents two implementations of the method and
displays some results.<br>
	<a href=./pdfs/non-local_means_denoising.pdf>Télécharger pdf</a>


<li> <b>Titre</b>: Numerical study of an optimization problem for mosaic
active imaging (2014) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : In this paper, we focus on the restoration of an image in mosaic active imaging. This emerging imaging technique consists in acquiring a mosaic of images (laser shots) by focusing
a laser beam on a small portion of the target object and subsequently moving it to scan the whole field of view. To restore
the whole image from such a mosaic, a prior work proposed a
simplified forward model describing the acquisition process.
It also provides a prior on the acquisition parameters. Together with a prior on the distribution of images, this leads to
a MAP estimate alternating between the estimation of the restored image and the estimation of these parameters. The novelty of the current paper is twofold: (i) We provide a numerical study and argue that faster convergence can be achieved
for estimating the acquisition parameters; (ii) we show that
the results from this earlier work are improved when the laser
shots are acquired according to a more compact pattern.<br>
	<a href=./pdfs/numerical_study_of_an_optimization_problem_for_mosaic_active_imaging.pdf>Télécharger pdf</a>

<li> <b>Titre</b>: Rectangular Decomposition of Binary Images (2012) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : The contribution deals with the most important methods for
decomposition of binary images into union of rectangles. The overview includes run-length encoding and its generalization, decompositions based
on quadtrees, on the distance transformation, and a theoretically optimal decomposition based on maximal matching in bipartite graphs.
We experimentally test their performance in binary image compression
and in convolution calculation and compare their computation times and
success rates.<br>
	<a href=./pdfs/rectangular_decomposition_of_binary_images.pdf>Télécharger pdf</a>

<li> <b>Titre</b>: An Experimental Comparison of Min-Cut/Max-Flow Algorithms for Energy Minimization in Vision (2004) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 3 <br>
     <b>Résumé</b> : After [15, 31, 19, 8, 25, 5] minimum cut/maximum flow algorithms on graphs emerged as
an increasingly useful tool for exact or approximate energy minimization in low-level vision.
The combinatorial optimization literature provides many min-cut/max-flow algorithms with
different polynomial time complexity. Their practical efficiency, however, has to date been
studied mainly outside the scope of computer vision. The goal of this paper is to provide an
experimental comparison of the efficiency of min-cut/max flow algorithms for applications
in vision. We compare the running times of several standard algorithms, as well as a
new algorithm that we have recently developed. The algorithms we study include both
Goldberg-Tarjan style “push-relabel” methods and algorithms based on Ford-Fulkerson
style “augmenting paths”. We benchmark these algorithms on a number of typical graphs
in the contexts of image restoration, stereo, and segmentation. In many cases our new
algorithm works several times faster than any of the other methods making near real-time
performance possible. An implementation of our max-flow/min-cut algorithm is available
upon request for research purposes.<br>
	<a href=./pdfs/an_experimental_comparison_of_gc_algorithms_for_energy_minimization_in_vision.pdf>Télécharger pdf</a>

<li> <b>Titre</b>: Efficient Graph Cut Optimization for Shape From Focus (2018) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 3 <br>
     <b>Résumé</b> : Shape From Focus refers to the problem of recovering the depth in every point
of a scene from a set of differently focused 2D images. Recently, some authors
stated this inverse problem in the variational framework and solved it by minimizing a non-convex functional. However, global optimality on the solution is
not guaranted and evaluations are either application-specific or incomplete. To
overcome these limits, we propose in this paper to globally and efficiently minimize a convex functional by decomposing it into a sequence of binary problems
using graph cuts. To illustrate the genericity of such a decomposition-based
approach, we investigate several decomposition strategies. Specifically, we focus
on data-driven strategies suited to early reconstruction. We provide qualitative and quantitative evaluation on real popular datasets. According to classic
statistics on error values, the proposed approach exhibits high performance and
robustness against corruped data.<br>
	<a href=./pdfs/efficient_graph_cut_optimization_for_shape_from_focus.pdf>Télécharger pdf</a>

<li> <b>Titre</b>: Fast and Efficient Reconstruction of Digitized Frescoes (2020) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 2 <br>
     <b>Résumé</b> : Virtually recomposing destroyed frescoes is of great importance for heritage conservation.  Given adigitized  fresco  image  and  a  digitized  set  of  fragments,  such  a  problem  is  challenging  due  to  the potentially large number of fragments,  their irregular shape,  uniqueness and non-overlapping constraints, the possible absence of fragments and the possible presence of small, homogeneous, erodedand/or spurious fragments.  To cope with these specific features, we propose in this paper a fast and efficient non-dense approach benefiting from previous developments in pattern matching. Preliminary experiments led on simulations exhibit a mean accuracy above 90% with a mean translation error of less than 4 pixels and a mean orientation error of about 1 degree.  An analysis of fresco and fragment features impacting the algorithm is also provided. Compared to a dense approach and the recent DeepMatch approach, the proposed one remains competitive both in running time and accuracy.<br>
	<a href=./pdfs/fast_and_efficient_reconstruction_of_digitized_frescoes.pdf>Télécharger pdf</a>

<li> <b>Titre</b>: Geometric Feature Extraction by a Multi-Marked Point Process (2009) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 3 <br>
     <b>Résumé</b> :This paper presents a new stochastic marked point process for describing images in terms of a finite library of geometric
objects. Image analysis based on conventional marked point processes has already produced convincing results but at the expense
of easy parameter tuning, short computing time, and unspecific models. Our more general multi-marked point process has simpler
parametric setting, yields notably shorter computing times and can be applied to a variety of applications. Both linear and areal
primitives extracted from a library of geometric objects are matched to a given image using a probabilistic Gibbs model, and a Jump-Diffusion process is performed to search for the optimal object configuration. Experiments with remotely sensed images and natural
textures show the proposed approach has good potential. We conclude with a discussion about the insertion of more complex object
interactions in the model by studying the compromise between model complexity and efficiency.<br>
	<a href=./pdfs/geometric_feature_extraction_by_a_multi-marked_point_process.pdf>Télécharger pdf</a>


<li> <b>Titre</b>: What Energy Functions Can Be Minimized via Graph Cuts? (2004) <b><FONT COLOR="green"> (disponible)</FONT></b><br>
     <b>Nombre d’étudiants</b>: 3 <br>
     <b>Résumé</b> :In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization
problems in computer vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the
energy. Yet, because these graph constructions are complex and highly specific to a particular energy function, graph cuts have seen
limited application to date. In this paper, we give a characterization of the energy functions that can be minimized by graph cuts. Our
results are restricted to functions of binary variables. However, our work generalizes many previous constructions and is easily
applicable to vision problems that involve large numbers of labels, such as stereo, motion, image restoration, and scene reconstruction.
We give a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be
written as a sum of terms containing three or fewer binary variables. We also provide a general-purpose construction to minimize such an
energy function. Finally, we give a necessary condition for any energy function of binary variables to be minimized by graph cuts.
Researchers who are considering the use of graph cuts to optimize a particular energy function can use our results to determine if this is
possible and then follow our construction to create the appropriate graph. A software implementation is freely available.<br>
	<a href=./pdfs/what_energy_functions_can_be_minimized_via_graph_cuts_2004.pdf>Télécharger pdf</a>


</ol>


</div></div></div>
</body></html>
